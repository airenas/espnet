{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SMSw_r1uRm4a"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/espnet/notebook/blob/master/tts_realtime_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuhqhYSToxl7"
   },
   "source": [
    "# ESPnet LT real time E2E-TTS demonstration\n",
    "\n",
    "This notebook provides a demonstration of the realtime E2E-TTS using ESPnet-TTS and ParallelWaveGAN (+ MelGAN).\n",
    "\n",
    "- ESPnet: https://github.com/airenas/espnet\n",
    "- ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN\n",
    "\n",
    "Author: Airenas Vaičiūnas ([airenass@gmail.com](https://github.com/airenas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9e_i_gdgAFNJ"
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjJ5zkyaoy29"
   },
   "outputs": [],
   "source": [
    "!pip install -q parallel_wavegan PyYaml unidecode ConfigArgparse \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/avaiciunas/gfs/tts/espnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lMJyJcLCsd4"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "## LT demo. Select trained model from egs/lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWaOkhGVQNla"
   },
   "source": [
    "#### (a) Tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCM9Eo2cPXhZ"
   },
   "outputs": [],
   "source": [
    "# set path\n",
    "trans_type = \"char\"\n",
    "dict_path = \"egs/sabina/tts1/data/lang_1char/char_train_no_dev_units.txt\"\n",
    "model_path = \"egs/sabina/tts1/exp/char_train_no_dev_pytorch_train_pytorch_tacotron2/results/model.last1.avg.best\"\n",
    "\n",
    "print(\"sucessfully set prepared models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ztWZjy_XOPZR"
   },
   "outputs": [],
   "source": [
    "# set path\n",
    "trans_type = \"char\"\n",
    "dict_path = \"egs/sabina/tts1/data/lang_1char/char_train_no_dev_units.txt\"\n",
    "model_path = \"egs/sabina/tts1/exp/char_train_no_dev_pytorch_train_pytorch_transformer.v3.single/results/model.loss.best\"\n",
    "#model_path = \"../egs/sabina/tts1/exp/char_train_no_dev_pytorch_train_pytorch_tacotron2/results/snapshot.ep.500\"\n",
    "\n",
    "print(\"sucessfully set prepared models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwc7JXD_dAy8"
   },
   "source": [
    "### Download pretrained vocoder model\n",
    "\n",
    "You can select one from two models. Please only run the seletected model cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdIFfyL9eWic"
   },
   "source": [
    "#### (a) Parallel WaveGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQDFNuQ2dK-M"
   },
   "outputs": [],
   "source": [
    "# download pretrained model\n",
    "import os\n",
    "if not os.path.exists(\"downloads/en/parallel_wavegan\"):\n",
    "    !utils/download_from_google_drive.sh \\\n",
    "        https://drive.google.com/open?id=1Grn7X9wD35UcDJ5F7chwdTqTa4U7DeVB downloads/en/parallel_wavegan tar.gz\n",
    "\n",
    "# set path\n",
    "vocoder_path = \"downloads/en/parallel_wavegan/ljspeech.parallel_wavegan.v2/checkpoint-400000steps.pkl\"\n",
    "vocoder_conf = \"downloads/en/parallel_wavegan/ljspeech.parallel_wavegan.v2/config.yml\"\n",
    "\n",
    "print(\"Sucessfully finished download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5B0V2Wy6ebNE"
   },
   "source": [
    "#### (b) MelGAN\n",
    "\n",
    "This is an **EXPERIMENTAL** model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBBAokMQegdK"
   },
   "outputs": [],
   "source": [
    "# download pretrained model\n",
    "import os\n",
    "if not os.path.exists(\"downloads/en/melgan\"):\n",
    "    !utils/download_from_google_drive.sh \\\n",
    "        https://drive.google.com/open?id=1ipPWYl8FBNRlBFaKj1-i23eQpW_W_YcR downloads/en/melgan tar.gz\n",
    "\n",
    "# set path\n",
    "vocoder_path = \"downloads/en/melgan/train_nodev_ljspeech_melgan.v1.long/checkpoint-1000000steps.pkl\"\n",
    "vocoder_conf = \"downloads/en/melgan/train_nodev_ljspeech_melgan.v1.long/config.yml\"\n",
    "\n",
    "print(\"Sucessfully finished download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaSyEKBWAK7H"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8JXOfRfqMFN"
   },
   "outputs": [],
   "source": [
    "# add path\n",
    "import sys\n",
    "sys.path.append(\"egs/lab/tts1/local\")\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "# define device\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# define E2E-TTS model\n",
    "from argparse import Namespace\n",
    "from espnet.asr.asr_utils import get_model_conf\n",
    "from espnet.asr.asr_utils import torch_load\n",
    "from espnet.utils.dynamic_import import dynamic_import\n",
    "idim, odim, train_args = get_model_conf(model_path)\n",
    "model_class = dynamic_import(train_args.model_module)\n",
    "model = model_class(idim, odim, train_args)\n",
    "torch_load(model_path, model)\n",
    "model = model.eval().to(device)\n",
    "inference_args = Namespace(**{\"threshold\": 0.5, \"minlenratio\": 0.0, \"maxlenratio\": 10.0})\n",
    "\n",
    "# define neural vocoder\n",
    "import yaml\n",
    "import parallel_wavegan.models\n",
    "with open(vocoder_conf) as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "vocoder_class = config.get(\"generator_type\", \"ParallelWaveGANGenerator\")\n",
    "vocoder = getattr(parallel_wavegan.models, vocoder_class)(**config[\"generator_params\"])\n",
    "vocoder.load_state_dict(torch.load(vocoder_path, map_location=\"cpu\")[\"model\"][\"generator\"])\n",
    "vocoder.remove_weight_norm()\n",
    "vocoder = vocoder.eval().to(device)\n",
    "\n",
    "# define text frontend\n",
    "with open(dict_path) as f:\n",
    "    lines = f.readlines()\n",
    "lines = [line.replace(\"\\n\", \"\").split(\" \") for line in lines]\n",
    "char_to_id = {c: int(i) for c, i in lines}\n",
    "def frontend(text):\n",
    "    \"\"\"Clean text and then convert to id sequence.\"\"\"\n",
    "    if trans_type == \"phn\":\n",
    "        text = filter(lambda s: s != \" \", g2p(text))\n",
    "        text = \" \".join(text)\n",
    "        print(f\"Cleaned text: {text}\")\n",
    "        charseq = text.split(\" \")\n",
    "    else:\n",
    "        print(f\"Cleaned text: {text}\")\n",
    "        charseq = list(text)\n",
    "    idseq = []\n",
    "    for c in charseq:\n",
    "        if c.isspace():\n",
    "            idseq += [char_to_id[\"<space>\"]]\n",
    "        elif c not in char_to_id.keys():\n",
    "            idseq += [char_to_id[\"<unk>\"]]\n",
    "        else:\n",
    "            idseq += [char_to_id[c]]\n",
    "    idseq += [idim - 1]  # <eos>\n",
    "    return torch.LongTensor(idseq).view(-1).to(device)\n",
    "\n",
    "print(\"Now ready to synthesize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AacD_RerASiO"
   },
   "source": [
    "### Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gGRzrjyudWF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "input_text = \"apie tai šeštadienio rytą socialiniame tinkle paskelbė miesto meras vytautas grubliauskas, aiškėja,\"\n",
    "\n",
    "pad_fn = torch.nn.ReplicationPad1d(\n",
    "    config[\"generator_params\"].get(\"aux_context_window\", 0))\n",
    "use_noise_input = vocoder_class == \"ParallelWaveGANGenerator\"\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    x = frontend(input_text)\n",
    "    print(f\"x = {x}\")\n",
    "    c, _, _ = model.inference(x, inference_args)\n",
    "    c = pad_fn(c.unsqueeze(0).transpose(2, 1)).to(device)\n",
    "    xx = (c,)\n",
    "    amStart = time.time() \n",
    "    elapsed = (amStart - start)\n",
    "    print(f\"acustic model done: {elapsed:5f} s\")\n",
    "    if use_noise_input:\n",
    "        z_size = (1, 1, (c.size(2) - sum(pad_fn.padding)) * config[\"hop_size\"])\n",
    "        z = torch.randn(z_size).to(device)\n",
    "        xx = (z,) + xx\n",
    "    y = vocoder(*xx).view(-1)\n",
    "    elapsed = (time.time() - amStart)\n",
    "    print(f\"vocoder done:       {elapsed:5f} s\")\n",
    "rtf = (time.time() - start) / (len(y) / config[\"sampling_rate\"])\n",
    "print(f\"RTF = {rtf:5f}\")\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "display(Audio(y.view(-1).cpu().numpy(), rate=config[\"sampling_rate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3lMJyJcLCsd4",
    "gtSZpF-mCjTr",
    "98SCpId7__5S"
   ],
   "name": "E2E-TTS demo のコピー",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
