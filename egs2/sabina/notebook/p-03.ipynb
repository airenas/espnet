{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuhqhYSToxl7"
   },
   "source": [
    "# ESPnet2-TTS realtime demonstration\n",
    "\n",
    "This notebook provides a demonstration of the realtime E2E-TTS using ESPnet2-TTS and ParallelWaveGAN (+ MelGAN).\n",
    "\n",
    "- ESPnet2-TTS: https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE/tts1\n",
    "- ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN\n",
    "\n",
    "Author: Tomoki Hayashi ([@kan-bayashi](https://github.com/kan-bayashi)), Airenas Vaičiūnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e_i_gdgAFNJ"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjJ5zkyaoy29"
   },
   "outputs": [],
   "source": [
    "# NOTE: pip shows imcompatible errors due to preinstalled libraries but you do not need to care\n",
    "!pip install -q espnet==0.9.5 parallel_wavegan==0.4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYLn3bL-qQjN"
   },
   "source": [
    "## Single speaker model demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as4iFXid0m4f"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ4ra5DcwwGI"
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#          SABINA MODELS         #\n",
    "###################################\n",
    "fs, lang = 22050, \"Lithuanian\"\n",
    "tag_dir= \"/home/avaiciunas/gfs/tts/espnet/egs2/sabina/tts1/p-03/exp/tts_train_raw_phn_none\"\n",
    "tag = \"train.loss.best.pth\"\n",
    "\n",
    "vocoder_path=(\"/home/avaiciunas/gfs/tts/ParallelWaveGAN/egs/sabina/voc1/exp/\" \n",
    "    \"train_nodev_ljspeech_parallel_wavegan.v3/checkpoint-700000steps.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9S-SFPe0z0w"
   },
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z64fD2UgjJ6Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "from parallel_wavegan.utils import download_pretrained_model\n",
    "from parallel_wavegan.utils import load_model\n",
    "mf = {'train_config': tag_dir + '/config-run.yaml',\n",
    " 'model_file': tag_dir + \"/\" + tag}\n",
    "dev=\"cpu\"\n",
    "text2speech = Text2Speech(\n",
    "    **mf,\n",
    "    device=dev,\n",
    "    # Only for Tacotron 2\n",
    "    threshold=0.5,\n",
    "    minlenratio=0.0,\n",
    "    maxlenratio=10.0,\n",
    "    use_att_constraint=False,\n",
    "    backward_window=1,\n",
    "    forward_window=3,\n",
    "    # Only for FastSpeech & FastSpeech2\n",
    "    speed_control_alpha=1.0,\n",
    ")\n",
    "text2speech.spc2wav = None  # Disable griffin-lim\n",
    "vocoder = load_model(vocoder_path).to(dev).eval()\n",
    "vocoder.remove_weight_norm()\n",
    "def rtf(start, end, w_len):\n",
    "  return (end - start) / (w_len / fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMaT0Zev021a"
   },
   "source": [
    "### Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrRM57hhgtHy"
   },
   "outputs": [],
   "source": [
    "# decide the input sentence by yourself\n",
    "x = (\"sil s t ai g \\\"a k a Z' \\\"i N.' k' ie n ^o: r a ^N. k o: s \\\"i S \\\"u S p a k a l' io:\" \n",
    "     \" u s p \\\"au d' E: j \\\"e: m. a k' \\\"i s i ^r. t ^ai p' n' e t' i k' \\\"E: t ai ,\"\n",
    "     \" k \\\"a t' j \\\"i s' n' ^e: t k r \\\"u: p' t' e l' E: j io: . sil\")\n",
    "# synthesis\n",
    "with torch.no_grad():\n",
    "    start_am = time.time()\n",
    "    wav, c, *_ = text2speech(x)\n",
    "    end_am = time.time()\n",
    "    wav = vocoder.inference(c)\n",
    "    end_voc = time.time()\n",
    "print(f\"RTF all = {rtf(start_am, end_voc, len(wav)):5f}, time = {(end_voc - start_am):5f}s\")\n",
    "print(f\"RTF am  = {rtf(start_am, end_am, len(wav)):5f}, time = {(end_am - start_am):5f}s\")\n",
    "print(f\"RTF voc = {rtf(end_am, end_voc, len(wav)):5f}, time = {(end_voc - end_am):5f}s\")\n",
    "\n",
    "# let us listen to generated samples\n",
    "from IPython.display import display, Audio\n",
    "display(Audio(wav.view(-1).cpu().numpy(), rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "espnet2_tts_demo",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
