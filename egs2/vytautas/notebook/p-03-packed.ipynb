{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMSw_r1uRm4a"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuhqhYSToxl7"
   },
   "source": [
    "# ESPnet2-TTS realtime demonstration\n",
    "\n",
    "This notebook provides a demonstration of the realtime E2E-TTS using ESPnet2-TTS and ParallelWaveGAN (+ MelGAN).\n",
    "\n",
    "- ESPnet2-TTS: https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE/tts1\n",
    "- ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN\n",
    "\n",
    "Author: Tomoki Hayashi ([@kan-bayashi](https://github.com/kan-bayashi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e_i_gdgAFNJ"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjJ5zkyaoy29"
   },
   "outputs": [],
   "source": [
    "# NOTE: pip shows imcompatible errors due to preinstalled libraries but you do not need to care\n",
    "!pip install -q espnet==0.9.5 parallel_wavegan==0.4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYLn3bL-qQjN"
   },
   "source": [
    "## Single speaker model demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as4iFXid0m4f"
   },
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ4ra5DcwwGI"
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#          SABINA MODELS         #\n",
    "###################################\n",
    "fs, lang = 22050, \"Lithuanian\"\n",
    "tag = \"./../tts1/p-03-1/exp/tts_train_raw_phn_none/tts_train_raw_phn_none_train.loss.ave.zip\"\n",
    "tag = \"/home/avaiciunas/gfs/tts/espnet/egs2/sabina/tts1/p-03old/exp/tts_train_raw_phn_none/tts_train_raw_phn_none_36epoch.zip\"\n",
    "\n",
    "vocoder_tag = \"ljspeech_parallel_wavegan.v1\"\n",
    "vocoder_path=(\"/home/avaiciunas/gfs/tts/ParallelWaveGAN/egs/sabina/voc1/exp/\" \n",
    "    \"train_nodev_ljspeech_parallel_wavegan.v3/checkpoint-710000steps.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9S-SFPe0z0w"
   },
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z64fD2UgjJ6Q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "from parallel_wavegan.utils import download_pretrained_model\n",
    "from parallel_wavegan.utils import load_model\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "d = ModelDownloader(\"~/.cache/espnet\") \n",
    "dev=\"cpu\"\n",
    "print(d.download_and_unpack(tag))\n",
    "text2speech = Text2Speech(\n",
    "    **d.download_and_unpack(tag),\n",
    "    device=dev,\n",
    "    # Only for Tacotron 2\n",
    "    threshold=0.5,\n",
    "    minlenratio=0.0,\n",
    "    maxlenratio=10.0,\n",
    "    use_att_constraint=True,\n",
    "    backward_window=1,\n",
    "    forward_window=3,\n",
    "    # Only for FastSpeech & FastSpeech2\n",
    "    speed_control_alpha=1.0,\n",
    ")\n",
    "text2speech.spc2wav = None  # Disable griffin-lim\n",
    "# NOTE: Sometimes download is failed due to \"Permission denied\". That is \n",
    "#   the limitation of google drive. Please retry after serveral hours.\n",
    "# vocoder = load_model(download_pretrained_model(vocoder_tag)).to(dev).eval()\n",
    "vocoder = load_model(vocoder_path).to(dev).eval()\n",
    "vocoder.remove_weight_norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMaT0Zev021a"
   },
   "source": [
    "### Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrRM57hhgtHy"
   },
   "outputs": [],
   "source": [
    "# decide the input sentence by yourself\n",
    "x = (\"sil s t ai g \\\"a k a Z' \\\"i N.' k' ie n ^o: r a ^N. k o: s \\\"i S \\\"u S p a k a l' io:\" \n",
    "     \" u s p \\\"au d' E: j \\\"e: m. a k' \\\"i s i ^r. t ^ai p' n' e t' i k' \\\"E: t ai ,\"\n",
    "     \" k \\\"a t' j \\\"i s' n' ^e: t k r \\\"u: p' t' e l' E: j io: . sil\")\n",
    "\n",
    "# synthesis\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    wav, c, *_ = text2speech(x)\n",
    "    wav = vocoder.inference(c)\n",
    "rtf = (time.time() - start) / (len(wav) / fs)\n",
    "print(f\"RTF = {rtf:5f}\")\n",
    "\n",
    "# let us listen to generated samples\n",
    "from IPython.display import display, Audio\n",
    "display(Audio(wav.view(-1).cpu().numpy(), rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "espnet2_tts_demo",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
